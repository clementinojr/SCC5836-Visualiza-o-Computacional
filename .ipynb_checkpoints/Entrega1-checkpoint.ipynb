{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003b439e-4ee5-4787-a7a1-f47203b54d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import mahotas \n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#from Features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc523d-e270-4e58-87e4-093a24da68ab",
   "metadata": {},
   "source": [
    "As imagens utilizadas são disponibilizadas no formato DICOM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4563dd-ebbf-43ec-a982-22682a59e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "==============================================================================\n",
    "@author: Nikolaos Giakoumoglou\n",
    "@date: Thu May  6 21:59:57 2021\n",
    "==============================================================================\n",
    "A.1 First Order Statistics/Statistical Features\n",
    "==============================================================================\n",
    "Inputs:\n",
    "    - f:        image of dimensions N1 x N2\n",
    "    - mask:     int boolean image N1 x N2 with 1 if pixels belongs to ROI, \n",
    "                0 else\n",
    "Outputs:\n",
    "    - features: 1)Mean, 2)Variance, 3)Median (50-Percentile), 4)Mode, \n",
    "                5)Skewness, 6)Kurtosis, 7)Energy, 8)Entropy, \n",
    "                9)Minimal Gray Level, 10)Maximal Gray Level, \n",
    "                11)Coefficient of Variation, 12,13,14,15)10,25,75,90-\n",
    "                Percentile, 16)Histogram width\n",
    "==============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fos(f, mask):\n",
    "    \n",
    "    # 1) Labels\n",
    "    labels = [\"FOS_Mean\",\"FOS_Variance\",\"FOS_Median\",\"FOS_Mode\",\"FOS_Skewness\",\n",
    "              \"FOS_Kurtosis\",\"FOS_Energy\",\"FOS_Entropy\",\"FOS_MinimalGrayLevel\",\n",
    "              \"FOS_MaximalGrayLevel\",\"FOS_CoefficientOfVariation\",\n",
    "              \"FOS_10Percentile\",\"FOS_25Percentile\",\"FOS_75Percentile\",\n",
    "              \"FOS_90Percentile\",\"FOS_HistogramWidth\"]\n",
    "    \n",
    "    # 2) Parameters\n",
    "    f  = f.astype(np.uint8)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    level_min = 0\n",
    "    level_max = 255\n",
    "    Ng = (level_max - level_min) + 1\n",
    "    bins = Ng\n",
    "    \n",
    "    # 3) Calculate Histogram H inside ROI\n",
    "    f_ravel = f.ravel() \n",
    "    mask_ravel = mask.ravel() \n",
    "    roi = f_ravel[mask_ravel.astype(bool)] \n",
    "    H = np.histogram(roi, bins=bins, range=[level_min, level_max], density=True)[0]\n",
    "    \n",
    "    # 4) Calculate Features\n",
    "    features = np.zeros(16,np.double)  \n",
    "    i = np.arange(0,bins)\n",
    "    features[0] = np.dot(i,H)\n",
    "    features[1] = sum(np.multiply(((i-features[0])**2),H))\n",
    "    features[2] = np.percentile(roi,50) \n",
    "    features[3] = np.argmax(H)\n",
    "    features[4] = sum(np.multiply(((i-features[0])**3),H))/(np.sqrt(features[1])**3)\n",
    "    features[5] = sum(np.multiply(((i-features[0])**4),H))/(np.sqrt(features[1])**4)\n",
    "    features[6] = sum(np.multiply(H,H))\n",
    "    features[7] = -sum(np.multiply(H,np.log(H+1e-16)))\n",
    "    features[8] = min(roi)\n",
    "    features[9] = max(roi)\n",
    "    features[10] = np.sqrt(features[2]) / features[0]\n",
    "    features[11] = np.percentile(roi,10) \n",
    "    features[12] = np.percentile(roi,25)  \n",
    "    features[13] = np.percentile(roi,75) \n",
    "    features[14] = np.percentile(roi,90) \n",
    "    features[15] = features[14] - features[11]\n",
    "    \n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea429d2-4f9f-4267-88df-072a586a543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Função que realiza a extrações de características de imagens em uma pasta\n",
    "def ExtractFeatureDataset(path):\n",
    "    images_path = os.listdir(path)\n",
    "    data = []\n",
    "    for n, image in enumerate(images_path):\n",
    "        print('Extraindo: ', image, ' Category:', os.path.basename(os.path.normpath(path)), ' Quantidade: ', n, '/', len(images_path))\n",
    "        img = cv2.imread(os.path.join(path, image))\n",
    "        #resize_ratio = 0.5\n",
    "        #img = maintain_aspect_ratio_resize(img, width=int(img.shape[1] * resize_ratio))\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.max(2)\n",
    "        mask = np.ones((img.shape[0], img.shape[1]))\n",
    "        feature_1 = fos(img, mask)[0]\n",
    "        print('FOS-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        aux_feature = glcm_features(img)\n",
    "        feature_2 = np.hstack([aux_feature[0], aux_feature[1]])\n",
    "        print('GLCM-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_3 = glds_features(img, mask)[0]\n",
    "        #print('GLDS-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_4 = ngtdm_features(img, mask, 8)[0]\n",
    "        #print('NGTDM-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_5 = sfm_features(img, mask)[0]\n",
    "       # print('SGM-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_6 = lte_measures(img, mask, 3)[0]\n",
    "        # print('LTE-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        # feature_7 = fps(img, mask)[0]\n",
    "        # print('FPS-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        # feature_8 = lbp_features_no_mask(img, 8, 2)\n",
    "        #print('LBP-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        feature_9 = lpq_features(img, 7)\n",
    "        print('LPQ-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_10 = cv2.HuMoments(cv2.moments(img_gray)).flatten()\n",
    "        #print('HUMoments-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "        #feature_11 = np.hstack([feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7])\n",
    "        #print('COMBINATION1-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "       # feature_12 = np.hstack([feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9, feature_10])\n",
    "        #print('COMBINATION2-Extraido, %s Segundos' % round((time.time() - start_time),2) )\n",
    "\n",
    "        imgData = imageData()\n",
    "        imgData.name = image\n",
    "        imgData.feature1 = list(feature_1)\n",
    "        imgData.feature2 = list(feature_2)\n",
    "        # imgData.feature3 = list(feature_3)\n",
    "        # imgData.feature4 = list(feature_4)\n",
    "        # imgData.feature5 = list(feature_5)\n",
    "        # imgData.feature6 = list(feature_6)\n",
    "        # imgData.feature7 = list(feature_7)\n",
    "        # imgData.feature8 = list(feature_8)\n",
    "        imgData.feature9 = list(feature_9)\n",
    "        # imgData.feature10 = list(feature_10)\n",
    "        # imgData.feature11 = list(feature_11)\n",
    "        # imgData.feature12 = list(feature_12)\n",
    "        imgData.category = os.path.basename(os.path.normpath(path))\n",
    "        data.append(imgData)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c866fc68-f764-46ec-9af5-5efd0ab2ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "==============================================================================\n",
    "@author: Nikolaos Giakoumoglou\n",
    "@date: Thu May  6 19:10:11 2021\n",
    "@reference: [7] Haralick, Textural Features for Image Classification\n",
    "==============================================================================\n",
    "A.2 Gray Level Co-occurence Matrix/Spatial Gray level Difference Matrix\n",
    "==============================================================================\n",
    "Inputs:\n",
    "    - f:             image of dimensions N1 x N2\n",
    "    - d:             distance to calculate Co-occurence matrix (default d=1)\n",
    "    - th:            angle to calculate Co-occurence matrix \n",
    "                     (default th=[0,45,90,135])\n",
    "    - ignore_zeros:  ignoore zeros due to mask (default True)\n",
    "Outputs:\n",
    "    - features:      Haralick's 1)Angular Second Moment, 2)Contrast, \n",
    "                     3)Correlation, 4)Sum of Squares: Variance, 5)Inverse \n",
    "                     Difference Moment 6)Sum Average, 7)Sum Variance, 8)Sum \n",
    "                     Entropy, 9)Entropy, 10)Difference Variance, 11)Difference \n",
    "                     Entropy, 12)Information Measure of Correlation 1, \n",
    "                     13)Information Measure of Correlation 2, 14)Maximal \n",
    "                     Correlation Coefficient    \n",
    "==============================================================================\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import mahotas\n",
    "\n",
    "def glcm_features(f, ignore_zeros=True):\n",
    "    \n",
    "    # 1) Labels\n",
    "    labels = [\"GLCM_ASM\", \"GLCM_Contrast\", \"GLCM_Correlation\",\n",
    "              \"GLCM_SumOfSquaresVariance\", \"GLCM_InverseDifferenceMoment\",\n",
    "               \"GLCM_SumAverage\", \"GLCM_SumVariance\", \"GLCM_SumEntropy\",\n",
    "               \"GLCM_Entropy\", \"GLCM_DifferenceVariance\",\n",
    "               \"GLCM_DifferenceEntropy\", \"GLCM_Information1\",\n",
    "               \"GLCM_Information2\", \"GLCM_MaximalCorrelationCoefficient\"]\n",
    "    labels_mean = [label + \"_Mean\" for label in labels]\n",
    "    labels_range = [label + \"_Range\" for label in labels]\n",
    "    \n",
    "    # 2) Parameters\n",
    "    f = f.astype(np.uint8)\n",
    "    \n",
    "    # 3) Calculate Features: Mean and Range\n",
    "    features = mahotas.features.haralick(f, \n",
    "                                         ignore_zeros=True, \n",
    "                                         compute_14th_feature=True,\n",
    "                                         return_mean_ptp=True)\n",
    "    features_mean = features[0:14]\n",
    "    features_range = features[14:]\n",
    "    \n",
    "    return features_mean, features_range, labels_mean, labels_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dae9fbd-c653-4458-bb66-b47453447054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def lpq_features(img,winSize=3,freqestim=1,mode='nh'):\n",
    "    rho=0.90\n",
    "\n",
    "    STFTalpha=1/winSize  # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "    sigmaS=(winSize-1)/4 # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "    sigmaA=8/(winSize-1) # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "\n",
    "    convmode='valid' # Compute descriptor responses only on part that have full neigborhood. Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "\n",
    "    img=np.float64(img) # Convert np.image to double\n",
    "    r=(winSize-1)/2 # Get radius from window size\n",
    "    x=np.arange(-r,r+1)[np.newaxis] # Form spatial coordinates in window\n",
    "\n",
    "    if freqestim==1:  #  STFT uniform window\n",
    "        #  Basic STFT filters\n",
    "        w0=np.ones_like(x)\n",
    "        w1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2=np.conj(w1)\n",
    "\n",
    "    ## Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "    # Run first filter\n",
    "    filterResp1=convolve2d(convolve2d(img,w0.T,convmode),w1,convmode)\n",
    "    filterResp2=convolve2d(convolve2d(img,w1.T,convmode),w0,convmode)\n",
    "    filterResp3=convolve2d(convolve2d(img,w1.T,convmode),w1,convmode)\n",
    "    filterResp4=convolve2d(convolve2d(img,w1.T,convmode),w2,convmode)\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "    freqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                        filterResp2.real, filterResp2.imag,\n",
    "                        filterResp3.real, filterResp3.imag,\n",
    "                        filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    ## Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "    LPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "    ## Switch format to uint8 if LPQ code np.image is required as output\n",
    "    if mode=='im':\n",
    "        LPQdesc=np.uint8(LPQdesc)\n",
    "\n",
    "    ## Histogram if needed\n",
    "    if mode=='nh' or mode=='h':\n",
    "        LPQdesc=np.histogram(LPQdesc.flatten(),range(256))[0]\n",
    "\n",
    "    ## Normalize histogram if needed\n",
    "    if mode=='nh':\n",
    "        LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "\n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e0c04b-4cc6-42f3-8aae-e464171dd61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo:  Fig -1 -Backes (1).png  Category: Testecovid  Quantidade:  0 / 1\n",
      "FOS-Extraido, 4647.43 Segundos\n",
      "GLCM-Extraido, 4647.54 Segundos\n",
      "LPQ-Extraido, 4647.75 Segundos\n",
      "Extraindo:  Fig -1 -Backes (1).png  Category: Testenormal  Quantidade:  0 / 1\n",
      "FOS-Extraido, 4647.81 Segundos\n",
      "GLCM-Extraido, 4647.92 Segundos\n",
      "LPQ-Extraido, 4648.12 Segundos\n"
     ]
    }
   ],
   "source": [
    "class imageData(object):\n",
    "    __slots__ = ['name', \n",
    "                'feature1', \n",
    "                'feature2', \n",
    "                'feature3', \n",
    "                'feature4', \n",
    "                'feature5',\n",
    "                'feature6',\n",
    "                'feature7',\n",
    "                'feature8',\n",
    "                'feature9',\n",
    "                'feature10',\n",
    "                'feature11',\n",
    "                'feature12',\n",
    "                'category']\n",
    "\n",
    "img1 = imageData()\n",
    "img1.name = 'imagem'\n",
    "folder_path_covid = \"C:/Users/junin/Documents/Testecovid\"\n",
    "folder_path_normais = \"C:/Users/junin/Documents/Testenormal\"\n",
    "dataCovid = ExtractFeatureDataset(folder_path_covid)\n",
    "dataNormal = ExtractFeatureDataset(folder_path_normais)\n",
    "#dataIntersticial = ExtractFeatureDataset(folder_path_intersticiais)\n",
    "#dataViral = ExtractFeatureDataset(folder_path_viral)\n",
    "\n",
    "##Combinando para gerar uma lista só para exportarção em CSV\n",
    "combineData = np.append(dataCovid, dataNormal)\n",
    "#combineData2 = np.append(combineData, dataIntersticial)\n",
    "dataSet = combineData\n",
    "\n",
    "##Titulo de cada atributo\n",
    "fieldnames = ['Image', \n",
    "              'Feature1', \n",
    "              'Feature2', \n",
    "            #   'Feature3', \n",
    "            #   'Feature4', \n",
    "            #   'Feature5',\n",
    "            #   'Feature6',\n",
    "            #   'Feature7',\n",
    "            #   'Feature8',\n",
    "              'Feature9',\n",
    "            #   'Feature10',\n",
    "            #   'Feature11',\n",
    "            #   'Feature12',\n",
    "              'Category']\n",
    "\n",
    "##Função que exporta a lista de extrações em CSV \n",
    "def WriteCSVFile(path, fieldnames, dataset):\n",
    "    file = open(path, 'w', newline='', encoding='utf-8')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(fieldnames)\n",
    "    for data in dataset:\n",
    "        objImg = [data.name, \n",
    "                  data.feature1, \n",
    "                  data.feature2, \n",
    "                #   data.feature3, \n",
    "                #   data.feature4, \n",
    "                #   data.feature5, \n",
    "                #   data.feature6, \n",
    "                #   data.feature7, \n",
    "                #   data.feature8,\n",
    "                  data.feature9, \n",
    "                #   data.feature10, \n",
    "                #   data.feature11, \n",
    "                #   data.feature12, \n",
    "                  data.category]\n",
    "        writer.writerow(objImg)\n",
    "\n",
    "WriteCSVFile('C:/Users/junin/Documents/Kdataset_texture_features_raiox.csv',fieldnames, dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fe3ac-7ce3-47a5-ae3d-10828f9b50ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf563d5-573c-48d1-aa98-1f67bc984beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_visu",
   "language": "python",
   "name": "env_visu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
